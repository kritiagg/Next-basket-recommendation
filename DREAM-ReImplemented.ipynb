{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import constants\n",
    "from config import Config\n",
    "from utils import batchify, repackage_hidden\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import cPickle as pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from time import time\n",
    "from math import ceil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from utils import pool_max, pool_avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class BasketConstructor(object):\n",
    "    '''\n",
    "        Group products into baskets(type: list)\n",
    "    '''\n",
    "    def __init__(self, raw_data_dir, cache_dir):\n",
    "        self.raw_data_dir = raw_data_dir\n",
    "        self.cache_dir = cache_dir\n",
    "    \n",
    "    def get_orders(self):\n",
    "        '''\n",
    "            get order context information\n",
    "        '''\n",
    "        orders = pd.read_csv(self.raw_data_dir + 'orders.csv')\n",
    "        orders = orders.fillna(0.0)\n",
    "        orders['days'] = orders.groupby(['user_id'])['days_since_prior_order'].cumsum()\n",
    "        orders['days_last'] = orders.groupby(['user_id'])['days'].transform(max)\n",
    "        orders['days_up_to_last'] = orders['days_last'] - orders['days']\n",
    "        del orders['days_last']\n",
    "        del orders['days']\n",
    "        return orders\n",
    "    \n",
    "    def get_orders_items(self, prior_or_train):\n",
    "        '''\n",
    "            get detailed information of prior or train orders \n",
    "        '''\n",
    "        orders_products = pd.read_csv(self.raw_data_dir + 'order_products__%s.csv'%prior_or_train)\n",
    "        return orders_products\n",
    "    \n",
    "\n",
    "    def get_users_orders(self, prior_or_train):\n",
    "        '''\n",
    "            get users' prior detailed orders\n",
    "        '''\n",
    "        if os.path.exists(self.cache_dir + 'users_orders.pkl'):\n",
    "            with open(self.cache_dir + 'users_orders.pkl', 'rb') as f:\n",
    "                users_orders = pickle.load(f)\n",
    "        else:\n",
    "            orders = self.get_orders()\n",
    "            order_products_prior = self.get_orders_items(prior_or_train)\n",
    "            users_orders = pd.merge(order_products_prior, orders[['user_id', 'order_id', 'order_number', 'days_up_to_last']], \n",
    "                        on = ['order_id'], how = 'left')\n",
    "            with open(self.cache_dir + 'users_orders.pkl', 'wb') as f:\n",
    "                pickle.dump(users_orders, f, pickle.HIGHEST_PROTOCOL)\n",
    "        return users_orders\n",
    "    \n",
    "    def get_users_products(self, prior_or_train):\n",
    "        '''\n",
    "            get users' all purchased products\n",
    "        '''\n",
    "        if os.path.exists(self.cache_dir + 'users_products.pkl'):\n",
    "            with open(self.cache_dir + 'users_products.pkl', 'rb') as f:\n",
    "                users_products = pickle.load(f)\n",
    "        else:\n",
    "            users_products = self.get_users_orders(prior_or_train)[['user_id', 'product_id']].drop_duplicates()\n",
    "            users_products['product_id'] = users_products.product_id.astype(int)\n",
    "            users_products['user_id'] = users_products.user_id.astype(int)\n",
    "            users_products = users_products.groupby(['user_id'])['product_id'].apply(list).reset_index()\n",
    "            with open(self.cache_dir + 'users_products.pkl', 'wb') as f:\n",
    "                pickle.dump(users_products, f, pickle.HIGHEST_PROTOCOL)\n",
    "        return users_products\n",
    "\n",
    "    def get_items(self, gran):\n",
    "        '''\n",
    "            get items' information\n",
    "            gran = [departments, aisles, products]\n",
    "        '''\n",
    "        items = pd.read_csv(self.raw_data_dir + '%s.csv'%gran)\n",
    "        return items\n",
    "    \n",
    "    def get_baskets(self, prior_or_train, reconstruct = False, reordered = False, none_idx = 49689):\n",
    "        '''\n",
    "            get users' baskets\n",
    "        '''\n",
    "        if reordered:\n",
    "            filepath = self.cache_dir + './reorder_basket_' + prior_or_train + '.pkl'\n",
    "        else:\n",
    "            filepath = self.cache_dir + './basket_' + prior_or_train + '.pkl'\n",
    "       \n",
    "        if (not reconstruct) and os.path.exists(filepath):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                up_basket = pickle.load(f)\n",
    "        else:          \n",
    "            up = self.get_users_orders(prior_or_train).sort_values(['user_id', 'order_number', 'product_id'], ascending = True)\n",
    "            uid_oid = up[['user_id', 'order_number']].drop_duplicates()\n",
    "            up = up[up.reordered == 1][['user_id', 'order_number', 'product_id']] if reordered else up[['user_id', 'order_number', 'product_id']]\n",
    "            # https://stackoverflow.com/questions/41856173/pandas-groupby-list\n",
    "            up_basket = up.groupby(['user_id', 'order_number'])['product_id'].apply(list).reset_index()\n",
    "            up_basket = pd.merge(uid_oid, up_basket, on = ['user_id', 'order_number'], how = 'left')\n",
    "            for row in up_basket.loc[up_basket.product_id.isnull(), 'product_id'].index:\n",
    "                up_basket.at[row, 'product_id'] = [none_idx]\n",
    "            up_basket = up_basket.sort_values(['user_id', 'order_number'], ascending = True).groupby(['user_id'])['product_id'].apply(list).reset_index()\n",
    "            up_basket.columns = ['user_id', 'reorder_basket'] if reordered else ['user_id', 'basket']\n",
    "            pdb.set_trace()\n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(up_basket, f, pickle.HIGHEST_PROTOCOL)\n",
    "        return up_basket\n",
    "        \n",
    "    def get_item_history(self, prior_or_train, reconstruct = False, none_idx = 49689):\n",
    "        filepath = self.cache_dir + './item_history_' + prior_or_train + '.pkl'\n",
    "        if (not reconstruct) and os.path.exists(filepath):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                item_history = pickle.load(f)\n",
    "        else:\n",
    "            up = self.get_users_orders(prior_or_train).sort_values(['user_id', 'order_number', 'product_id'], ascending = True)\n",
    "            item_history = up.groupby(['user_id', 'order_number'])['product_id'].apply(list).reset_index()\n",
    "            item_history.loc[item_history.order_number == 1, 'product_id'] = item_history.loc[item_history.order_number == 1, 'product_id'] + [none_idx]\n",
    "            # Do we need this?\n",
    "            item_history = item_history.sort_values(['user_id', 'order_number'], ascending = True)\n",
    "            # accumulate \n",
    "            item_history['product_id'] = item_history.groupby(['user_id'])['product_id'].transform(pd.Series.cumsum)\n",
    "            # get unique item list\n",
    "            item_history['product_id'] = item_history['product_id'].apply(set).apply(list)\n",
    "            \n",
    "            # Do we need this?\n",
    "            item_history = item_history.sort_values(['user_id', 'order_number'], ascending = True)\n",
    "            # shift each group to make it history\n",
    "            item_history['product_id'] = item_history.groupby(['user_id'])['product_id'].shift(1)\n",
    "            for row in item_history.loc[item_history.product_id.isnull(), 'product_id'].index:\n",
    "                item_history.at[row, 'product_id'] = [none_idx]\n",
    "            # Is this sufficient?\n",
    "            item_history = item_history.sort_values(['user_id', 'order_number'], ascending = True).groupby(['user_id'])['product_id'].apply(list).reset_index()\n",
    "            item_history.columns = ['user_id', 'history_items']\n",
    "\n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(item_history, f, pickle.HIGHEST_PROTOCOL)\n",
    "        return item_history       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    '''\n",
    "        Dataset prepare from user-basket\n",
    "    '''\n",
    "    def __init__(self, up_basket, up_r_basket = None, up_his = None):\n",
    "        if (up_r_basket is not None) and (up_his is not None):\n",
    "            self.is_reordered_included = True\n",
    "        else:\n",
    "            self.is_reordered_included = False\n",
    "\n",
    "        up_basket['num_baskets'] = up_basket.basket.apply(len)\n",
    "        self.user_id = list(up_basket.user_id)\n",
    "        self.num_baskets = [int(n) for n in list(up_basket.num_baskets)]    \n",
    "        self.basket = [[[int(p) for p in b]for b in u] for u in list(up_basket.basket)]\n",
    "\n",
    "        if self.is_reordered_included is True:\n",
    "            up_basket = pd.merge(up_basket, up_r_basket, on = ['user_id'], how = 'left')\n",
    "            up_basket = pd.merge(up_basket, up_his, on = ['user_id'], how = 'left')\n",
    "            self.reorder_basket = [[[int(p) for p in b]for b in u] for u in list(up_basket.reorder_basket)]\n",
    "            self.history_item = [[[int(p) for p in b]for b in u] for u in list(up_basket.history_items)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "            return baskets & num_baskets\n",
    "        '''\n",
    "        if self.is_reordered_included is True:\n",
    "            return self.basket[index], self.num_baskets[index], self.user_id[index], self.reorder_basket[index], self.history_item[index]\n",
    "        else:\n",
    "            return self.basket[index], self.num_baskets[index], self.user_id[index]\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dream.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class DreamModel(torch.nn.Module):\n",
    "    '''\n",
    "       Input Data: b_1, ... b_i ..., b_t\n",
    "                   b_i stands for user u's ith basket\n",
    "                   b_i = [p_1,..p_j...,p_n]\n",
    "                   p_j stands for the  jth product in user u's ith basket\n",
    "    '''\n",
    "    def __init__(self, config):\n",
    "        super(DreamModel, self).__init__()\n",
    "        # Model configuration\n",
    "        self.config = config\n",
    "        # Layer definitons\n",
    "        self.encode = torch.nn.Embedding(config.num_product, \n",
    "                                         config.embedding_dim,\n",
    "                                         padding_idx = 0) # Item embedding layer\n",
    "        self.pool = {'avg':pool_avg, 'max':pool_max}[config.basket_pool_type] # Pooling of basket\n",
    "        # RNN type specify\n",
    "        if config.rnn_type in ['LSTM', 'GRU']:\n",
    "            self.rnn = getattr(torch.nn, config.rnn_type)(config.embedding_dim, \n",
    "                                                          config.embedding_dim, \n",
    "                                                          config.rnn_layer_num, \n",
    "                                                          batch_first=True, \n",
    "                                                          dropout=config.dropout)\n",
    "        else:\n",
    "            nonlinearity = {'RNN_TANH': 'tanh', 'RNN_RELU': 'relu'}[config.rnn_type]\n",
    "            self.rnn = torch.nn.RNN(config.embedding_dim, \n",
    "                                    config.embedding_dim, \n",
    "                                    config.rnn_layer_num, \n",
    "                                    nonlinearity=nonlinearity, \n",
    "                                    batch_first=True, \n",
    "                                    dropout=config.dropout)\n",
    "    \n",
    "    def forward(self, x, lengths, hidden):\n",
    "        pdb.set_trace()\n",
    "        # Basket Encoding \n",
    "        ub_seqs = [] # users' basket sequence\n",
    "        for user in x: # x shape (batch of user, time_step, indice of product) nested lists\n",
    "            embed_baskets = []\n",
    "            for basket in user:\n",
    "                basket = torch.LongTensor(basket).resize_(1, len(basket))\n",
    "                basket = basket.cuda() if self.config.cuda else basket # use cuda for acceleration\n",
    "                basket = self.encode(torch.autograd.Variable(basket)) # shape: 1, len(basket), embedding_dim\n",
    "                embed_baskets.append(self.pool(basket, dim = 1))\n",
    "            # concat current user's all baskets and append it to users' basket sequence\n",
    "            try:\n",
    "                ub_seqs.append(torch.cat(embed_baskets, 1)) # shape: 1, num_basket, embedding_dim\n",
    "            except:\n",
    "                pdb.set_trace()\n",
    "        \n",
    "        # Input for rnn \n",
    "        ub_seqs = torch.cat(ub_seqs, 0).cuda() if self.config.cuda else torch.cat(ub_seqs, 0) # shape: batch_size, max_len, embedding_dim\n",
    "        packed_ub_seqs = torch.nn.utils.rnn.pack_padded_sequence(ub_seqs, lengths, batch_first=True) # packed sequence as required by pytorch\n",
    "        \n",
    "        # RNN\n",
    "        output, h_u = self.rnn(packed_ub_seqs, hidden)\n",
    "        dynamic_user, _ = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True) # shape: batch_size, max_len, embedding_dim\n",
    "        return dynamic_user, h_u\n",
    "        \n",
    "    def init_weight(self):\n",
    "        # Init item embedding\n",
    "        initrange = 0.1\n",
    "        self.encode.weight.data.uniform_(-initrange, initrange)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # Init hidden states for rnn\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.config.rnn_type == 'LSTM':\n",
    "            return (Variable(weight.new(self.config.rnn_layer_num, batch_size, self.config.embedding_dim).zero_()),\n",
    "                    Variable(weight.new(self.config.rnn_layer_num, batch_size, self.config.embedding_dim).zero_()))\n",
    "        else:\n",
    "            return Variable(weight.new(self.config.rnn_layer_num, batch_size, self.config.embedding_dim).zero_())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bc done...\n"
     ]
    }
   ],
   "source": [
    "# CUDA environtments\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,3,2,1\"\n",
    "\n",
    "# Prepare input\n",
    "bc = BasketConstructor(constants.RAW_DATA_DIR, constants.FEAT_DATA_DIR)\n",
    "print(\"bc done...\")\n",
    "ub_basket = bc.get_baskets('prior', reconstruct = False)\n",
    "train_ub, test_ub = train_test_split(ub_basket, test_size = 0.2)\n",
    "del ub_basket\n",
    "# train_ub, test_ub = Dataset(train_ub), Dataset(test_ub)\n",
    "dr_config = Config(constants.DREAM_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14678</th>\n",
       "      <td>14679</td>\n",
       "      <td>[[1541, 2536, 5031, 14788, 17670, 18115, 24838...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>3061</td>\n",
       "      <td>[[29933], [14631, 23892], [7046, 8152, 23892, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5749</th>\n",
       "      <td>5750</td>\n",
       "      <td>[[852, 4216, 10957, 12513, 14111, 14325, 23957...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12707</th>\n",
       "      <td>12708</td>\n",
       "      <td>[[26968], [327, 5618, 15872, 16759, 17419, 213...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23285</th>\n",
       "      <td>23286</td>\n",
       "      <td>[[8671, 12392, 19382, 25069, 25146, 27344, 294...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17559</th>\n",
       "      <td>17560</td>\n",
       "      <td>[[2450, 4920, 10644, 21137, 28934, 30190, 3134...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12762</th>\n",
       "      <td>12763</td>\n",
       "      <td>[[890, 2846, 9698, 9839, 11125, 30720, 34126, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17133</th>\n",
       "      <td>17134</td>\n",
       "      <td>[[4210, 5077, 5818, 8424, 12087, 14502, 24622,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24079</th>\n",
       "      <td>24080</td>\n",
       "      <td>[[432, 8309, 13176, 14084, 15991, 16083, 35547...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12501</th>\n",
       "      <td>12502</td>\n",
       "      <td>[[4605, 19446, 23909, 24852, 43961], [10840, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9315</th>\n",
       "      <td>9316</td>\n",
       "      <td>[[38768], [5769, 32689, 38768], [3798, 21195, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30335</th>\n",
       "      <td>30336</td>\n",
       "      <td>[[416, 25466, 26112, 31506, 33548, 47037], [40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21423</th>\n",
       "      <td>21424</td>\n",
       "      <td>[[3583, 6218, 15698, 19467, 24852, 28934], [75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31373</th>\n",
       "      <td>31374</td>\n",
       "      <td>[[1281, 10479, 13176, 14161, 20561, 22963, 277...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>464</td>\n",
       "      <td>[[9036, 13984, 20734, 24964, 28785, 31662, 427...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>3801</td>\n",
       "      <td>[[2102, 25146, 41276], [41276], [25146, 45054]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22649</th>\n",
       "      <td>22650</td>\n",
       "      <td>[[3177, 9741, 14168, 19263, 26493, 27294, 2801...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19660</th>\n",
       "      <td>19661</td>\n",
       "      <td>[[5769, 11266, 22218, 25588, 27845, 29223, 317...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12853</th>\n",
       "      <td>12854</td>\n",
       "      <td>[[9270, 27949, 29071, 39475], [6972, 9896, 115...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24045</th>\n",
       "      <td>24046</td>\n",
       "      <td>[[6184, 12341, 16797, 17207], [12341], [12341,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13467</th>\n",
       "      <td>13468</td>\n",
       "      <td>[[6740, 7963, 10017, 13984, 20034, 21903, 2620...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9865</th>\n",
       "      <td>9866</td>\n",
       "      <td>[[287, 11614, 11798, 13022, 18539, 20126, 2411...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19365</th>\n",
       "      <td>19366</td>\n",
       "      <td>[[16797, 22475, 28842, 29487, 32303, 35042, 44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27370</th>\n",
       "      <td>27371</td>\n",
       "      <td>[[2732, 11249, 12014, 14897, 18770, 19478, 282...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23642</th>\n",
       "      <td>23643</td>\n",
       "      <td>[[5876, 7552, 18465, 39005, 47734], [5785, 184...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28627</th>\n",
       "      <td>28628</td>\n",
       "      <td>[[20899, 21137, 29142, 37029, 38274, 38895], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16496</th>\n",
       "      <td>16497</td>\n",
       "      <td>[[16732, 45128], [1957, 9358], [13176, 13575],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4256</th>\n",
       "      <td>4257</td>\n",
       "      <td>[[18482, 30450, 33000], [18482], [18482], [184...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14072</th>\n",
       "      <td>14073</td>\n",
       "      <td>[[1194, 5353, 14947, 21938, 38383, 41844], [53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17507</th>\n",
       "      <td>17508</td>\n",
       "      <td>[[3626, 7166, 7628, 12791, 14188, 14992, 16185...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28320</th>\n",
       "      <td>28321</td>\n",
       "      <td>[[1405, 3223, 16965, 31810, 47357], [3223, 257...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29593</th>\n",
       "      <td>29594</td>\n",
       "      <td>[[5876, 7503, 8174, 9020, 10749, 13231, 15349,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13421</th>\n",
       "      <td>13422</td>\n",
       "      <td>[[24964, 27156], [4472, 6692, 8021, 11629, 122...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7809</th>\n",
       "      <td>7810</td>\n",
       "      <td>[[196, 2907, 5431, 6046, 10554, 20898, 24852, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6266</th>\n",
       "      <td>6267</td>\n",
       "      <td>[[651, 5456, 9038, 12919, 20061, 25931, 27000,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16646</th>\n",
       "      <td>16647</td>\n",
       "      <td>[[933, 3800, 4447, 6281, 7026, 8424, 8732, 182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15270</th>\n",
       "      <td>15271</td>\n",
       "      <td>[[7673, 20649, 21121, 21137, 26604, 27966, 392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>3762</td>\n",
       "      <td>[[2593, 11005, 12409, 13431, 14129, 16462, 184...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24289</th>\n",
       "      <td>24290</td>\n",
       "      <td>[[5130, 5373, 10749, 12845, 22888, 22935, 2496...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>1619</td>\n",
       "      <td>[[5496, 13984, 16797, 26209, 26604, 29694, 343...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26154</th>\n",
       "      <td>26155</td>\n",
       "      <td>[[4605, 5782, 7648, 9551, 10460, 10819, 23106,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7144</th>\n",
       "      <td>7145</td>\n",
       "      <td>[[329, 4614, 16797, 17758, 18465, 40198], [329...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10215</th>\n",
       "      <td>10216</td>\n",
       "      <td>[[44177], [44177], [25146], [5025], [8305, 256...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28596</th>\n",
       "      <td>28597</td>\n",
       "      <td>[[3990, 8638, 14233, 15703, 25647, 39216, 4160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6526</th>\n",
       "      <td>6527</td>\n",
       "      <td>[[12068, 14992, 16897, 19660, 22788, 25221, 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21791</th>\n",
       "      <td>21792</td>\n",
       "      <td>[[1215, 2450, 5303, 7021, 12745, 16994, 22035,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8771</th>\n",
       "      <td>8772</td>\n",
       "      <td>[[1071], [20955], [15200, 29694], [1071]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28055</th>\n",
       "      <td>28056</td>\n",
       "      <td>[[3952, 6218, 14506, 20908, 20980, 22857, 2293...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20831</th>\n",
       "      <td>20832</td>\n",
       "      <td>[[6341, 28092, 39275, 41866, 43248, 43409, 465...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31286</th>\n",
       "      <td>31287</td>\n",
       "      <td>[[2099, 14364], [14364, 19145, 29487], [1234, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22435</th>\n",
       "      <td>22436</td>\n",
       "      <td>[[29447], [5878], [22198, 25138, 27156], [2513...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13189</th>\n",
       "      <td>13190</td>\n",
       "      <td>[[20497, 28525, 29455, 36767, 43150, 45048], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12134</th>\n",
       "      <td>12135</td>\n",
       "      <td>[[13819, 19057, 39928, 43122], [19057, 39928],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14247</th>\n",
       "      <td>14248</td>\n",
       "      <td>[[4102, 4920, 9038, 11352, 13649, 13838, 15340...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20722</th>\n",
       "      <td>20723</td>\n",
       "      <td>[[1348, 9755, 13176, 21903, 25552, 28476, 3849...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26288</th>\n",
       "      <td>26289</td>\n",
       "      <td>[[1556, 4605, 8174, 8424, 13646, 13984, 16521,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21035</th>\n",
       "      <td>21036</td>\n",
       "      <td>[[234, 31808, 47877], [234, 10673, 14502, 1980...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8571</th>\n",
       "      <td>8572</td>\n",
       "      <td>[[11140, 11777, 21454, 26062, 37080, 40078, 41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30941</th>\n",
       "      <td>30942</td>\n",
       "      <td>[[5782, 45066], [5782], [5646, 5782, 16465, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20889</th>\n",
       "      <td>20890</td>\n",
       "      <td>[[16908, 18362, 21333, 23716, 28204, 28459, 33...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id                                             basket\n",
       "14678    14679  [[1541, 2536, 5031, 14788, 17670, 18115, 24838...\n",
       "3060      3061  [[29933], [14631, 23892], [7046, 8152, 23892, ...\n",
       "5749      5750  [[852, 4216, 10957, 12513, 14111, 14325, 23957...\n",
       "12707    12708  [[26968], [327, 5618, 15872, 16759, 17419, 213...\n",
       "23285    23286  [[8671, 12392, 19382, 25069, 25146, 27344, 294...\n",
       "17559    17560  [[2450, 4920, 10644, 21137, 28934, 30190, 3134...\n",
       "12762    12763  [[890, 2846, 9698, 9839, 11125, 30720, 34126, ...\n",
       "17133    17134  [[4210, 5077, 5818, 8424, 12087, 14502, 24622,...\n",
       "24079    24080  [[432, 8309, 13176, 14084, 15991, 16083, 35547...\n",
       "12501    12502  [[4605, 19446, 23909, 24852, 43961], [10840, 1...\n",
       "9315      9316  [[38768], [5769, 32689, 38768], [3798, 21195, ...\n",
       "30335    30336  [[416, 25466, 26112, 31506, 33548, 47037], [40...\n",
       "21423    21424  [[3583, 6218, 15698, 19467, 24852, 28934], [75...\n",
       "31373    31374  [[1281, 10479, 13176, 14161, 20561, 22963, 277...\n",
       "463        464  [[9036, 13984, 20734, 24964, 28785, 31662, 427...\n",
       "3800      3801  [[2102, 25146, 41276], [41276], [25146, 45054]...\n",
       "22649    22650  [[3177, 9741, 14168, 19263, 26493, 27294, 2801...\n",
       "19660    19661  [[5769, 11266, 22218, 25588, 27845, 29223, 317...\n",
       "12853    12854  [[9270, 27949, 29071, 39475], [6972, 9896, 115...\n",
       "24045    24046  [[6184, 12341, 16797, 17207], [12341], [12341,...\n",
       "13467    13468  [[6740, 7963, 10017, 13984, 20034, 21903, 2620...\n",
       "9865      9866  [[287, 11614, 11798, 13022, 18539, 20126, 2411...\n",
       "19365    19366  [[16797, 22475, 28842, 29487, 32303, 35042, 44...\n",
       "27370    27371  [[2732, 11249, 12014, 14897, 18770, 19478, 282...\n",
       "23642    23643  [[5876, 7552, 18465, 39005, 47734], [5785, 184...\n",
       "28627    28628  [[20899, 21137, 29142, 37029, 38274, 38895], [...\n",
       "16496    16497  [[16732, 45128], [1957, 9358], [13176, 13575],...\n",
       "4256      4257  [[18482, 30450, 33000], [18482], [18482], [184...\n",
       "14072    14073  [[1194, 5353, 14947, 21938, 38383, 41844], [53...\n",
       "17507    17508  [[3626, 7166, 7628, 12791, 14188, 14992, 16185...\n",
       "...        ...                                                ...\n",
       "28320    28321  [[1405, 3223, 16965, 31810, 47357], [3223, 257...\n",
       "29593    29594  [[5876, 7503, 8174, 9020, 10749, 13231, 15349,...\n",
       "13421    13422  [[24964, 27156], [4472, 6692, 8021, 11629, 122...\n",
       "7809      7810  [[196, 2907, 5431, 6046, 10554, 20898, 24852, ...\n",
       "6266      6267  [[651, 5456, 9038, 12919, 20061, 25931, 27000,...\n",
       "16646    16647  [[933, 3800, 4447, 6281, 7026, 8424, 8732, 182...\n",
       "15270    15271  [[7673, 20649, 21121, 21137, 26604, 27966, 392...\n",
       "3761      3762  [[2593, 11005, 12409, 13431, 14129, 16462, 184...\n",
       "24289    24290  [[5130, 5373, 10749, 12845, 22888, 22935, 2496...\n",
       "1618      1619  [[5496, 13984, 16797, 26209, 26604, 29694, 343...\n",
       "26154    26155  [[4605, 5782, 7648, 9551, 10460, 10819, 23106,...\n",
       "7144      7145  [[329, 4614, 16797, 17758, 18465, 40198], [329...\n",
       "10215    10216  [[44177], [44177], [25146], [5025], [8305, 256...\n",
       "28596    28597  [[3990, 8638, 14233, 15703, 25647, 39216, 4160...\n",
       "6526      6527  [[12068, 14992, 16897, 19660, 22788, 25221, 33...\n",
       "21791    21792  [[1215, 2450, 5303, 7021, 12745, 16994, 22035,...\n",
       "8771      8772          [[1071], [20955], [15200, 29694], [1071]]\n",
       "28055    28056  [[3952, 6218, 14506, 20908, 20980, 22857, 2293...\n",
       "20831    20832  [[6341, 28092, 39275, 41866, 43248, 43409, 465...\n",
       "31286    31287  [[2099, 14364], [14364, 19145, 29487], [1234, ...\n",
       "22435    22436  [[29447], [5878], [22198, 25138, 27156], [2513...\n",
       "13189    13190  [[20497, 28525, 29455, 36767, 43150, 45048], [...\n",
       "12134    12135  [[13819, 19057, 39928, 43122], [19057, 39928],...\n",
       "14247    14248  [[4102, 4920, 9038, 11352, 13649, 13838, 15340...\n",
       "20722    20723  [[1348, 9755, 13176, 21903, 25552, 28476, 3849...\n",
       "26288    26289  [[1556, 4605, 8174, 8424, 13646, 13984, 16521,...\n",
       "21035    21036  [[234, 31808, 47877], [234, 10673, 14502, 1980...\n",
       "8571      8572  [[11140, 11777, 21454, 26062, 37080, 40078, 41...\n",
       "30941    30942  [[5782, 45066], [5782], [5646, 5782, 16465, 21...\n",
       "20889    20890  [[16908, 18362, 21333, 23716, 28204, 28459, 33...\n",
       "\n",
       "[25600 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def bpr_loss(x, dynamic_user, item_embedding, config):\n",
    "    '''\n",
    "        bayesian personalized ranking loss for implicit feedback\n",
    "        parameters:\n",
    "        - x: batch of users' baskets\n",
    "        - dynamic_user: batch of users' dynamic representations\n",
    "        - item_embedding: item_embedding matrix\n",
    "        - config: model configuration\n",
    "    '''\n",
    "    nll = 0\n",
    "    ub_seqs = []\n",
    "    for u,du in zip(x, dynamic_user):\n",
    "        du_p_product = torch.mm(du, item_embedding.t()) # shape: max_len, num_item\n",
    "        nll_u = [] # nll for user\n",
    "        for t, basket_t in enumerate(u):\n",
    "            if basket_t[0] != 0 and t != 0:\n",
    "                pos_idx = torch.cuda.LongTensor(basket_t) if config.cuda else torch.LongTensor(basket_t)\n",
    "                # Sample negative products\n",
    "                neg = [random.choice(range(1, config.num_product)) for _ in range(len(basket_t))] # replacement\n",
    "                # neg = random.sample(range(1, config.num_product), len(basket_t)) # without replacement\n",
    "                neg_idx = torch.cuda.LongTensor(neg) if config.cuda else torch.LongTensor(neg)\n",
    "                # Score p(u, t, v > v')\n",
    "                score = du_p_product[t - 1][pos_idx] - du_p_product[t - 1][neg_idx]\n",
    "                #Average Negative log likelihood for basket_t\n",
    "                nll_u.append(- torch.mean(torch.nn.LogSigmoid()(score)))\n",
    "        nll += torch.mean(torch.cat(nll_u))\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_dream():\n",
    "    dr_model.train() # turn on training mode for dropout\n",
    "    dr_hidden = dr_model.init_hidden(dr_config.batch_size) \n",
    "    total_loss = 0\n",
    "    start_time = time()\n",
    "    num_batchs = ceil(len(train_ub) / dr_config.batch_size)\n",
    "    pdb.set_trace()\n",
    "    for i,x in enumerate(batchify(train_ub, dr_config.batch_size)):\n",
    "        baskets, lens, _ = x\n",
    "        dr_hidden = repackage_hidden(dr_hidden) # repackage hidden state for RNN\n",
    "        dr_model.zero_grad() # optim.zero_grad()\n",
    "        dynamic_user, _  = dr_model(baskets, lens, dr_hidden)\n",
    "        loss = bpr_loss(baskets, dynamic_user, dr_model.encode.weight, dr_config)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clip to avoid gradient exploding\n",
    "        torch.nn.utils.clip_grad_norm(dr_model.parameters(), dr_config.clip) \n",
    "\n",
    "        # Parameter updating\n",
    "        # manual SGD\n",
    "        # for p in dr_model.parameters(): # Update parameters by -lr*grad\n",
    "        #    p.data.add_(- dr_config.learning_rate, p.grad.data)\n",
    "        # adam \n",
    "        optim.step()\n",
    "\n",
    "        total_loss += loss.data\n",
    "        \n",
    "        # Logging\n",
    "        if i % dr_config.log_interval == 0 and i > 0:\n",
    "            elapsed = (time() - start_time) * 1000 / dr_config.log_interval\n",
    "            cur_loss = total_loss[0] / dr_config.log_interval # turn tensor into float\n",
    "            total_loss = 0\n",
    "            start_time = time()\n",
    "            print('[Training]| Epochs {:3f} | Batch {:5f} / {:5f} | ms/batch {:02.2f} | Loss {:05.2f} |'.format(epoch, i, num_batchs, elapsed, cur_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def evaluate_dream():\n",
    "    dr_model.eval()\n",
    "    dr_hidden = dr_model.init_hidden(dr_config.batch_size) \n",
    "    \n",
    "    total_loss = 0\n",
    "    start_time = time()\n",
    "    num_batchs = ceil(len(test_ub) / dr_config.batch_size)\n",
    "    for i,x in enumerate(batchify(test_ub, dr_config.batch_size)):\n",
    "        baskets, lens, _ = x\n",
    "        dynamic_user, _  = dr_model(baskets, lens, dr_hidden)\n",
    "        loss = bpr_loss(baskets, dynamic_user, dr_model.encode.weight, dr_config)\n",
    "        dr_hidden = repackage_hidden(dr_hidden)\n",
    "        total_loss += loss.data\n",
    "        \n",
    "    # Logging\n",
    "    elapsed = (time() - start_time) * 1000 / num_batchs\n",
    "    total_loss = total_loss[0] / num_batchs\n",
    "    print('[Evaluation]| Epochs {:3f} | Elapsed {:02.2f} | Loss {:05.2f} |'.format(epoch, elapsed, total_loss))\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr_coonfig done...\n",
      "<config.Config object at 0x10d979b90>\n",
      "('clip', 20)\n",
      "('dropout', 0.5)\n",
      "('batch_size', 4)\n",
      "('epochs', 100)\n",
      "('checkpoint_dir', '../Instacart/dream/reorder-next-dream-{epoch:02d}-{loss:.4f}.model')\n",
      "('basket_pool_type', 'max')\n",
      "('num_product', 49690)\n",
      "('embedding_dim', 64)\n",
      "('log_interval', 1)\n",
      "('learning_rate', 0.01)\n",
      "('rnn_layers', 1)\n",
      "('cuda', False)\n",
      "('none_idx', 49689)\n",
      "('rnn_type', 'LSTM')\n",
      "> <ipython-input-10-c20b6c70a6d0>(8)train_dream()\n",
      "-> for i,x in enumerate(batchify(train_ub, dr_config.batch_size)):\n",
      "(Pdb) train_ub.shape()\n",
      "*** AttributeError: 'Dataset' object has no attribute 'shape'\n",
      "(Pdb) train_ub.size()\n",
      "*** AttributeError: 'Dataset' object has no attribute 'size'\n",
      "(Pdb) len(train_ub)\n",
      "25600\n",
      "*****************************************************************************************\n",
      "Early Stopping!\n"
     ]
    }
   ],
   "source": [
    "dr_model = DreamModel(dr_config)\n",
    "if dr_config.cuda:\n",
    "    dr_model.cuda()\n",
    "print(\"dr_coonfig done...\")\n",
    "optim = torch.optim.Adam(dr_model.parameters(), lr = dr_config.learning_rate)\n",
    "\n",
    "best_val_loss = None\n",
    "\n",
    "try:\n",
    "    print(dr_config)\n",
    "    for k,v in constants.DREAM_CONFIG.items():\n",
    "        print(k,v)\n",
    "    # training\n",
    "    for epoch in range(dr_config.epochs):\n",
    "        train_dream()\n",
    "        # train_reorder_dream()\n",
    "        print('-' * 89)\n",
    "        val_loss = evaluate_dream()\n",
    "        # val_loss = evaluate_reorder_dream()\n",
    "        print('-' * 89)\n",
    "        # checkpoint\n",
    "        if not best_val_loss or val_loss < best_val_loss:\n",
    "            with open(dr_config.checkpoint_dir.format(epoch = epoch, loss = val_loss), 'wb') as f:\n",
    "                torch.save(dr_model, f)\n",
    "            best_val_loss = val_loss\n",
    "        else:\n",
    "            # Manual SGD slow down lr if no improvement in val_loss\n",
    "            # dr_config.learning_rate = dr_config.learning_rate / 4\n",
    "            pass\n",
    "except KeyboardInterrupt:\n",
    "    print('*' * 89)\n",
    "    print('Early Stopping!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "val_loss = evaluate_dream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ub_basket = bc.get_baskets('prior', reconstruct = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_ub, test_ub = train_test_split(ub_basket, test_size = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_ub, test_ub = Dataset(train_ub), Dataset(test_ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
